# ğŸ“Š Performance Testing â€“ Scalable Article Hub

This folder contains **JMeter test plans, results, and reports** used for performance evaluation of the Scalable Article Hub project.

---

## ğŸ“ Folder Structure

```aiignore
perf/
â”œâ”€â”€ keywords.csv # Test keywords dataset
â”œâ”€â”€ ids_hot.csv # Test ids dataset
â”œâ”€â”€ ids_random.csv # Test random dataset
â”œâ”€â”€ ids_zipf.csv # Test zipf dataset
â”œâ”€â”€ Compare MySQL vs ES.jmx # JMeter test plan for DB engine comparison
â”œâ”€â”€ keywordTest.jmx # Keyword-based search performance test
â”œâ”€â”€ perf.jmx # General performance test plan
â”œâ”€â”€ testplan.jmx # Main performance test plan (single endpoint)
â”œâ”€â”€ userLoads.jmx # Multi-thread-group test plan for user load scaling
â”œâ”€â”€ ArticleHub Cold.jmx # JMeter test plan for cache (cold)
â”œâ”€â”€ ArticleHub Hot.jmx # JMeter test plan for cache (hot)
â””â”€â”€ README.md # This documentation
```

---

## ğŸ§ª Test Plan Overview

### 1. `perf.jmx`
- Purpose: **General API performance test**
- Target: Main search endpoint
- Configuration:
    - Single Thread Group
    - Adjustable user count & loop count
    - Outputs: `result.jtl` + `report_html`

### 2. `userLoads.jmx`
- Purpose: **User load scaling test**
- Target: Search API under various loads
- Configuration:
    - Four Thread Groups: 1, 20, 100, 300 users
    - Each group runs the same keyword search scenario
    - Outputs: Keyword-based performance metrics

### 3. `Compare MySQL vs ES.jmx`
- Purpose: Compare **MySQL Search API** vs **Elasticsearch Search API**
- Configuration:
    - One Thread Group, 50 users Ã— 5 loops
    - Two HTTP Samplers (MySQL Search, ES Search)
    - Outputs: `result_compare_50.jtl` + `report_compare_50`

---

## âš¡ Cache Experiment

This section contains Redis caching experiments that evaluate hit/miss ratios under different access patterns.

ğŸ§ª Test Setup
```aiignore
Tool: JMeter 5.6

Cache: Redis 7.2 (Docker)

Workload: 100 requests per scenario


Patterns Tested:

  ğŸ”¥ Hot (same key repeatedly)
  
  ğŸ² Random (uniform random keys)
  
  ğŸ“Š Zipf (skewed popularity distribution)
```
### âœ… Key Findings

Hot access quickly achieves nearly 100% hit ratio once cache is warmed.

Random access benefits less from caching (â‰ˆ50% hit rate).

Zipf distribution shows strong cache efficiency due to skewed popularity (91% warm hit rate).

Cold starts always begin with 0â€“50% hit ratios depending on access locality.

---

## ğŸ“Š How to Run Tests

### GUI Mode
1. Open JMeter
2. Load `.jmx` file (e.g., `perf.jmx`)
3. Configure Thread Group parameters (users, loops)
4. Run and view results in **Summary Report** or **HTML Report Dashboard**

### CLI Mode
```bash
jmeter -n \
  -t perf/compare_mysql_es.jmx \
  -l perf/result_compare_50.jtl \
  -e -o perf/report_compare_50
```

---
ğŸš« Files Ignored in Git
- *.jtl â€“ Raw JMeter result files

- HTML report folders (*_html/) â€“ Can be regenerated from .jtl

---

ğŸ“Œ Notes
- All .jmx files are version-controlled

- Result files (.jtl) and reports are excluded via .gitignore

- To reproduce results, simply run the .jmx plans with JMeter